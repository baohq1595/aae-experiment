{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup\n",
    "- To use tsne on GPU (rapidAI)\n",
    "- Wandb tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 134
    },
    "colab_type": "code",
    "id": "gpWEFymIw5Hy",
    "outputId": "d44cedd3-2234-44ec-e354-6ffe8b41a53b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********************************************************************\n",
      "Let us check on those pyarrow and cffi versions...\n",
      "***********************************************************************\n",
      "\n",
      "You're don't have pyarrow.\n",
      "unloaded cffi 1.14.1\n",
      "loaded cffi 1.11.5\n"
     ]
    }
   ],
   "source": [
    "# Install RAPIDS\n",
    "!git clone https://github.com/rapidsai/rapidsai-csp-utils.git\n",
    "!bash rapidsai-csp-utils/colab/rapids-colab.sh stable\n",
    "\n",
    "import sys, os\n",
    "\n",
    "dist_package_index = sys.path.index('/usr/local/lib/python3.6/dist-packages')\n",
    "sys.path = sys.path[:dist_package_index] + ['/usr/local/lib/python3.6/site-packages'] + sys.path[dist_package_index:]\n",
    "sys.path\n",
    "exec(open('rapidsai-csp-utils/colab/update_modules.py').read(), globals())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "P6U08_CEixiG"
   },
   "outputs": [],
   "source": [
    "!pip install wandb -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "RbQ_E6aei4bQ",
    "outputId": "16300aa8-c550-4db4-efd9-c2513a5668b8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "# WandB â€“ Login to your wandb account so you can log all your metrics\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 84
    },
    "colab_type": "code",
    "id": "TEdHn0uti6m1",
    "outputId": "f585bceb-9311-413b-ac03-058f630d7229"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://app.wandb.ai/baohq/acai-mnist-tf\" target=\"_blank\">https://app.wandb.ai/baohq/acai-mnist-tf</a><br/>\n",
       "                Run page: <a href=\"https://app.wandb.ai/baohq/acai-mnist-tf/runs/26hax65u\" target=\"_blank\">https://app.wandb.ai/baohq/acai-mnist-tf/runs/26hax65u</a><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "W&B Run: https://app.wandb.ai/baohq/acai-mnist-tf/runs/26hax65u"
      ]
     },
     "execution_count": 4,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.init(project=\"acai-mnist-tf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "voJWBqhikNWN"
   },
   "source": [
    "### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7m6AVx78AiF1"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.layers import Input, Dense, Reshape, Flatten, Dropout, multiply, GaussianNoise\n",
    "from tensorflow.keras.layers import BatchNormalization, Activation, Embedding, ZeroPadding2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import LeakyReLU\n",
    "from tensorflow.keras.layers import UpSampling2D, Conv2D, Reshape\n",
    "from tensorflow.keras.layers import Lambda\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import losses\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.datasets import mnist\n",
    "import keras.backend as K\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import tqdm\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ACAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XvNABltRAkEj"
   },
   "outputs": [],
   "source": [
    "class ACAI():\n",
    "    def __init__(self, img_shape=(28,28), latent_dim=32, disc_reg_coef=0.2, ae_reg_coef=0.5, dropout=0.0):\n",
    "        self.latent_dim = latent_dim\n",
    "        self.ae_optim = Adam(0.0001)\n",
    "        self.d_optim = Adam(0.0001)\n",
    "        self.img_shape = img_shape\n",
    "        self.dropout = dropout\n",
    "        self.disc_reg_coef = disc_reg_coef\n",
    "        self.ae_reg_coef = ae_reg_coef\n",
    "        self.intitializer = tf.keras.initializers.VarianceScaling(\n",
    "                            scale=0.2, mode='fan_in', distribution='truncated_normal')\n",
    "        self.initialize_models(self.img_shape, self.latent_dim)\n",
    "\n",
    "    def initialize_models(self, img_shape, latent_dim):\n",
    "        self.encoder = self.build_encoder(img_shape, latent_dim)\n",
    "        self.decoder = self.build_decoder(latent_dim, img_shape)\n",
    "        self.discriminator = self.build_discriminator(latent_dim, img_shape)\n",
    "        \n",
    "        img = Input(shape=img_shape)\n",
    "        latent = self.encoder(img)\n",
    "        res_img = self.decoder(latent)\n",
    "        \n",
    "        self.autoencoder = Model(img, res_img)\n",
    "        discri_out = self.discriminator(img)\n",
    "\n",
    "\n",
    "    def build_encoder(self, img_shape, latent_dim):\n",
    "        encoder = Sequential(name='encoder')\n",
    "        encoder.add(Flatten(input_shape=img_shape))\n",
    "        encoder.add(Dense(1000, activation=tf.nn.leaky_relu, kernel_initializer=self.intitializer))\n",
    "        encoder.add(Dropout(self.dropout))\n",
    "        encoder.add(Dense(1000, activation=tf.nn.leaky_relu, kernel_initializer=self.intitializer))\n",
    "        encoder.add(Dropout(self.dropout))\n",
    "        encoder.add(Dense(latent_dim))\n",
    "        \n",
    "        encoder.summary()\n",
    "        return encoder\n",
    "    \n",
    "    def build_decoder(self, latent_dim, img_shape):\n",
    "        decoder = Sequential(name='decoder')\n",
    "        decoder.add(Dense(1000, input_dim=latent_dim, activation=tf.nn.leaky_relu, kernel_initializer=self.intitializer))\n",
    "        decoder.add(Dropout(self.dropout))\n",
    "        decoder.add(Dense(1000, activation=tf.nn.leaky_relu, kernel_initializer=self.intitializer))\n",
    "        decoder.add(Dropout(self.dropout))\n",
    "        decoder.add(Dense(np.prod(img_shape), activation='sigmoid'))\n",
    "        decoder.add(Reshape(img_shape))\n",
    "        \n",
    "        decoder.summary()\n",
    "        return decoder\n",
    "\n",
    "    def build_discriminator(self, latent_dim, img_shape):\n",
    "        discriminator = Sequential(name='discriminator')\n",
    "        discriminator.add(Flatten(input_shape=img_shape))\n",
    "        discriminator.add(Dense(1000, activation=tf.nn.leaky_relu, kernel_initializer=self.intitializer))\n",
    "        discriminator.add(Dropout(self.dropout))\n",
    "        discriminator.add(Dense(1000, activation=tf.nn.leaky_relu, kernel_initializer=self.intitializer))\n",
    "        discriminator.add(Dropout(self.dropout))\n",
    "        discriminator.add(Dense(latent_dim))\n",
    "\n",
    "        # discriminator.add(Reshape((-1,)))\n",
    "        discriminator.add(Lambda(lambda x: tf.reduce_mean(x, axis=1)))\n",
    "        \n",
    "        discriminator.summary()\n",
    "        return discriminator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Utils functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8jOJZDODAqGM"
   },
   "outputs": [],
   "source": [
    "import io\n",
    "from PIL import Image\n",
    "from sklearn.decomposition import PCA\n",
    "# from sklearn.manifold import TSNE\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "def make_image_grid(imgs, shape, prefix, save_path, is_show=False):\n",
    "    fig = plt.figure(figsize=[20,20])\n",
    "    for index, img in enumerate(imgs):\n",
    "        img = img.reshape(shape)\n",
    "        ax = fig.add_subplot(10, 10, index + 1)\n",
    "        ax.set_axis_off()\n",
    "        ax.imshow(img, cmap='gray')\n",
    "    fig.savefig(os.path.join(save_path, prefix + '.png'))\n",
    "    if is_show:\n",
    "        plt.show()\n",
    "    plt.close(fig)\n",
    "    img = Image.open(os.path.join(save_path, prefix + '.png'))\n",
    "\n",
    "    return img\n",
    "\n",
    "def flip_tensor(t):\n",
    "    a, b = tf.split(x, 2, axis=0)\n",
    "    return tf.concat([b, a], axis=0)\n",
    "\n",
    "def plot_to_image(figure):\n",
    "    \"\"\"Converts the matplotlib plot specified by 'figure' to a PNG image and\n",
    "    returns it. The supplied figure is closed and inaccessible after this call.\"\"\"\n",
    "    # Save the plot to a PNG in memory.\n",
    "    buf = io.BytesIO()\n",
    "    plt.savefig(buf, format='png')\n",
    "    # Closing the figure prevents it from being displayed directly inside\n",
    "    # the notebook.\n",
    "    plt.close(figure)\n",
    "    buf.seek(0)\n",
    "    # Convert PNG buffer to TF image\n",
    "    image = tf.image.decode_png(buf.getvalue(), channels=4)\n",
    "    # Add the batch dimension\n",
    "    image = tf.expand_dims(image, 0)\n",
    "    return image\n",
    "\n",
    "from cuml.manifold import TSNE\n",
    "def visualize_latent_space(x, labels, n_clusters, range_lim=(-80, 80), perplexity=40, is_save=False, save_path=None):\n",
    "    tsne = TSNE(n_components=2, verbose=0, perplexity=perplexity, n_iter=1000, init='random')\n",
    "    tsne_results = tsne.fit_transform(x)\n",
    "    df_subset = pd.DataFrame()\n",
    "    \n",
    "    df_subset['tsne-2d-one'] = tsne_results[:,0]\n",
    "    df_subset['tsne-2d-two'] = tsne_results[:,1]\n",
    "    df_subset['Y'] =  labels\n",
    "    \n",
    "    n_comps = len(np.unique(labels).tolist())\n",
    "    \n",
    "    plt.figure(figsize=(16,10))\n",
    "    sns_plot = sns.scatterplot(\n",
    "        x='tsne-2d-one', y='tsne-2d-two',\n",
    "        hue='Y',\n",
    "        palette=sns.color_palette(n_colors=n_comps),\n",
    "        data=df_subset,\n",
    "        legend=\"full\",\n",
    "        alpha=0.3\n",
    "    ).set(xlim=range_lim,ylim=range_lim)\n",
    "    \n",
    "    if is_save:\n",
    "        if not os.path.exists(os.path.dirname(save_path)):\n",
    "            os.makedirs(os.path.dirname(save_path))\n",
    "        save_path = save_path if save_path else ''\n",
    "        plt.savefig(save_path)\n",
    "        plt.close('all')\n",
    "        img = Image.open(save_path)\n",
    "        return img\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training procedure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Dof21I3aAx0O"
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_on_batch(x, y, model: ACAI):\n",
    "    # Randomzie interpolated coefficient alpha\n",
    "    alpha = tf.random.uniform((x.shape[0], 1), 0, 1)\n",
    "    alpha = 0.5 - tf.abs(alpha - 0.5)  # Make interval [0, 0.5]\n",
    "\n",
    "    with tf.GradientTape() as ae_tape, tf.GradientTape() as d_tape:\n",
    "        # Constructs non-interpolated latent space and decoded input\n",
    "        latent = model.encoder(x, training=True)\n",
    "        res_x = model.decoder(latent, training=True)\n",
    "\n",
    "        ae_loss = tf.reduce_mean(tf.losses.mean_squared_error(tf.reshape(x, (x.shape[0], -1)), tf.reshape(res_x, (res_x.shape[0], -1))))\n",
    "\n",
    "        inp_latent = alpha * latent + (1 - alpha) * latent[::-1]\n",
    "        res_x_hat = model.decoder(inp_latent, training=False)\n",
    "\n",
    "        pred_alpha = model.discriminator(res_x_hat, training=True)\n",
    "        # pred_alpha = K.mean(pred_alpha, [1,2,3])\n",
    "        temp = model.discriminator(res_x + model.disc_reg_coef * (x - res_x), training=True)\n",
    "        # temp = K.mean(temp, [1,2,3])\n",
    "        disc_loss_term_1 = tf.reduce_mean(tf.square(pred_alpha - alpha))\n",
    "        disc_loss_term_2 = tf.reduce_mean(tf.square(temp))\n",
    "\n",
    "        reg_ae_loss = model.ae_reg_coef * tf.reduce_mean(tf.square(pred_alpha))\n",
    "\n",
    "        total_ae_loss = ae_loss + reg_ae_loss\n",
    "        total_d_loss = disc_loss_term_1 + disc_loss_term_2\n",
    "\n",
    "    grad_ae = ae_tape.gradient(total_ae_loss, model.autoencoder.trainable_variables)\n",
    "    grad_d = d_tape.gradient(total_d_loss, model.discriminator.trainable_variables)\n",
    "\n",
    "    model.ae_optim.apply_gradients(zip(grad_ae, model.autoencoder.trainable_variables))\n",
    "    model.d_optim.apply_gradients(zip(grad_d, model.discriminator.trainable_variables))\n",
    "\n",
    "    return {\n",
    "        'res_ae_loss': ae_loss,\n",
    "        'reg_ae_loss': reg_ae_loss,\n",
    "        'disc_loss': disc_loss_term_1,\n",
    "        'reg_disc_loss': disc_loss_term_2\n",
    "\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UkIhjZlpND2L"
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "def avg_losses(total_losses):\n",
    "    flatten_losses = defaultdict(list)\n",
    "    for loss in total_losses:\n",
    "        for kv in loss.items():\n",
    "            flatten_losses[kv[0]].append(kv[1])\n",
    "\n",
    "    avg_loss = {kv[0]: sum(kv[1]) / len(kv[1]) for kv in flatten_losses.items()}\n",
    "\n",
    "    return avg_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1vcpHi8PAr_W"
   },
   "outputs": [],
   "source": [
    "def train(model: ACAI, x_train, y_train, x_test,\n",
    "          batch_size, epochs=1000, save_interval=200,\n",
    "          save_path='./images'):\n",
    "    n_epochs = tqdm.tqdm_notebook(range(epochs))\n",
    "    total_batches = x_train.shape[0] // batch_size\n",
    "    if not os.path.exists(save_path):\n",
    "        os.makedirs(save_path)\n",
    "    for epoch in n_epochs:\n",
    "        offset = 0\n",
    "        losses = []\n",
    "        random_idx = np.random.randint(0, x_train.shape[0], x_train.shape[0])\n",
    "        for batch_iter in range(total_batches):\n",
    "            # Randomly choose each half batch\n",
    "            imgs = x_train[offset:offset + batch_size,::] if (batch_iter < (total_batches - 1)) else x_train[offset:,::]\n",
    "            offset += batch_size\n",
    "\n",
    "            loss = train_on_batch(imgs, None, model)\n",
    "            losses.append(loss)\n",
    "\n",
    "        avg_loss = avg_losses(losses)\n",
    "        wandb.log({'losses': avg_loss})\n",
    "            \n",
    "        if epoch % save_interval == 0 or (epoch == epochs - 1):\n",
    "            sampled_imgs = model.autoencoder(x_test[:100])\n",
    "            res_img = make_image_grid(sampled_imgs.numpy(), (28,28), str(epoch), save_path)\n",
    "            \n",
    "            latent = model.encoder(x_train, training=False).numpy()\n",
    "            latent_space_img = visualize_latent_space(latent, y_train, 10, is_save=True, save_path=f'./latent_space/{epoch}.png')\n",
    "            wandb.log({'res_test_img': [wandb.Image(res_img, caption=\"Reconstructed images\")],\n",
    "                        'latent_space': [wandb.Image(latent_space_img, caption=\"Latent space\")]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "44609c79cb4742b1be7ffee7a0f8a394",
      "469a40d3ed734b3bbfc68c5973f122d3",
      "0072440b17514101aa4e842809f50329",
      "dc3809f31f774fe9be5e0a627e3f1ecb",
      "9d3ad8fc441148de91b9e1a0131dd0b7",
      "86a73da314a04fdca98f48f8f3c01072",
      "4440cae355354141a3f803d698880921",
      "9723f27f9ba64ce5ba8339ff478e9056"
     ]
    },
    "colab_type": "code",
    "id": "kYzFXeOPAzdL",
    "outputId": "7aaa7448-920e-4d75-dcce-44e73f4f0d79"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"encoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten (Flatten)            (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1000)              785000    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1000)              1001000   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 32)                32032     \n",
      "=================================================================\n",
      "Total params: 1,818,032\n",
      "Trainable params: 1,818,032\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"decoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_3 (Dense)              (None, 1000)              33000     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1000)              1001000   \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 784)               784784    \n",
      "_________________________________________________________________\n",
      "reshape (Reshape)            (None, 28, 28)            0         \n",
      "=================================================================\n",
      "Total params: 1,818,784\n",
      "Trainable params: 1,818,784\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"discriminator\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_1 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1000)              785000    \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1000)              1001000   \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 32)                32032     \n",
      "_________________________________________________________________\n",
      "lambda (Lambda)              (None,)                   0         \n",
      "=================================================================\n",
      "Total params: 1,818,032\n",
      "Trainable params: 1,818,032\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44609c79cb4742b1be7ffee7a0f8a394",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2000.0), HTML(value='')))"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train = x_train.astype(np.float32) / 255.\n",
    "x_test = x_test.astype(np.float32) / 255.\n",
    "ann = ACAI(dropout=0.5)\n",
    "train(model=ann,\n",
    "        x_train=x_train,\n",
    "        y_train=y_train,\n",
    "        x_test=x_test,\n",
    "        batch_size=x_train.shape[0]//4,\n",
    "        epochs=2000,\n",
    "        save_interval=50,\n",
    "        save_path='./images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67
    },
    "colab_type": "code",
    "id": "x3gWpGcrpMLi",
    "outputId": "f2a5fae7-7602-44fc-bd2e-5667449fdcf5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /content/wandb/run-20200815_154923-26hax65u/acai/discriminator/assets\n",
      "INFO:tensorflow:Assets written to: /content/wandb/run-20200815_154923-26hax65u/acai/encoder/assets\n",
      "INFO:tensorflow:Assets written to: /content/wandb/run-20200815_154923-26hax65u/acai/decoder/assets\n"
     ]
    }
   ],
   "source": [
    "# ann.autoencoder.save('acai/autoencoder')\n",
    "ann.discriminator.save('/content/wandb/run-20200815_154923-26hax65u/acai/discriminator')\n",
    "ann.encoder.save('/content/wandb/run-20200815_154923-26hax65u/acai/encoder')\n",
    "ann.decoder.save('/content/wandb/run-20200815_154923-26hax65u/acai/decoder')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 336
    },
    "colab_type": "code",
    "id": "hTVdV2dvv_iD",
    "outputId": "41dcb172-1f08-44c7-cd77-2f52a2059ceb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  adding: content/wandb/run-20200815_154923-26hax65u/acai/ (stored 0%)\n",
      "  adding: content/wandb/run-20200815_154923-26hax65u/acai/decoder/ (stored 0%)\n",
      "  adding: content/wandb/run-20200815_154923-26hax65u/acai/decoder/variables/ (stored 0%)\n",
      "  adding: content/wandb/run-20200815_154923-26hax65u/acai/decoder/variables/variables.data-00000-of-00001 (deflated 7%)\n",
      "  adding: content/wandb/run-20200815_154923-26hax65u/acai/decoder/variables/variables.index (deflated 46%)\n",
      "  adding: content/wandb/run-20200815_154923-26hax65u/acai/decoder/saved_model.pb (deflated 89%)\n",
      "  adding: content/wandb/run-20200815_154923-26hax65u/acai/decoder/assets/ (stored 0%)\n",
      "  adding: content/wandb/run-20200815_154923-26hax65u/acai/discriminator/ (stored 0%)\n",
      "  adding: content/wandb/run-20200815_154923-26hax65u/acai/discriminator/variables/ (stored 0%)\n",
      "  adding: content/wandb/run-20200815_154923-26hax65u/acai/discriminator/variables/variables.data-00000-of-00001 (deflated 7%)\n",
      "  adding: content/wandb/run-20200815_154923-26hax65u/acai/discriminator/variables/variables.index (deflated 45%)\n",
      "  adding: content/wandb/run-20200815_154923-26hax65u/acai/discriminator/saved_model.pb (deflated 89%)\n",
      "  adding: content/wandb/run-20200815_154923-26hax65u/acai/discriminator/assets/ (stored 0%)\n",
      "  adding: content/wandb/run-20200815_154923-26hax65u/acai/encoder/ (stored 0%)\n",
      "  adding: content/wandb/run-20200815_154923-26hax65u/acai/encoder/variables/ (stored 0%)\n",
      "  adding: content/wandb/run-20200815_154923-26hax65u/acai/encoder/variables/variables.data-00000-of-00001 (deflated 7%)\n",
      "  adding: content/wandb/run-20200815_154923-26hax65u/acai/encoder/variables/variables.index (deflated 45%)\n",
      "  adding: content/wandb/run-20200815_154923-26hax65u/acai/encoder/saved_model.pb (deflated 89%)\n",
      "  adding: content/wandb/run-20200815_154923-26hax65u/acai/encoder/assets/ (stored 0%)\n"
     ]
    }
   ],
   "source": [
    "!zip /content/wandb/run-20200815_154923-26hax65u/acai.zip -r /content/wandb/run-20200815_154923-26hax65u/acai/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_oh-D-k-BJto"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "acai-mnist-tf.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0072440b17514101aa4e842809f50329": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_86a73da314a04fdca98f48f8f3c01072",
      "max": 2000,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_9d3ad8fc441148de91b9e1a0131dd0b7",
      "value": 2000
     }
    },
    "4440cae355354141a3f803d698880921": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "44609c79cb4742b1be7ffee7a0f8a394": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_0072440b17514101aa4e842809f50329",
       "IPY_MODEL_dc3809f31f774fe9be5e0a627e3f1ecb"
      ],
      "layout": "IPY_MODEL_469a40d3ed734b3bbfc68c5973f122d3"
     }
    },
    "469a40d3ed734b3bbfc68c5973f122d3": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "86a73da314a04fdca98f48f8f3c01072": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9723f27f9ba64ce5ba8339ff478e9056": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9d3ad8fc441148de91b9e1a0131dd0b7": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "dc3809f31f774fe9be5e0a627e3f1ecb": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9723f27f9ba64ce5ba8339ff478e9056",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_4440cae355354141a3f803d698880921",
      "value": " 2000/2000 [50:38&lt;00:00,  1.52s/it]"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
